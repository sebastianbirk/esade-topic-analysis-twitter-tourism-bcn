{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://radimrehurek.com/gensim/models/hdpmodel.html\n",
    "# https://markroxor.github.io/gensim/static/notebooks/gensim_news_classification.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from gensim.models import HdpModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim import corpora\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log events\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Corpora and Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-23 15:07:55,653 : INFO : loading Dictionary object from tourism_no_pooling.dict\n",
      "2018-09-23 15:07:55,660 : INFO : loaded tourism_no_pooling.dict\n",
      "2018-09-23 15:07:55,665 : INFO : loaded corpus index from tourism_no_pooling.mm.index\n",
      "2018-09-23 15:07:55,666 : INFO : initializing cython corpus reader from tourism_no_pooling.mm\n",
      "2018-09-23 15:07:55,670 : INFO : accepted corpus with 7633 documents, 5035 features, 41550 non-zero entries\n",
      "2018-09-23 15:07:55,673 : INFO : loading Dictionary object from tourism_user_pooling.dict\n",
      "2018-09-23 15:07:55,678 : INFO : loaded tourism_user_pooling.dict\n",
      "2018-09-23 15:07:55,682 : INFO : loaded corpus index from tourism_user_pooling.mm.index\n",
      "2018-09-23 15:07:55,683 : INFO : initializing cython corpus reader from tourism_user_pooling.mm\n",
      "2018-09-23 15:07:55,688 : INFO : accepted corpus with 4424 documents, 4185 features, 33668 non-zero entries\n",
      "2018-09-23 15:07:55,692 : INFO : loading Dictionary object from tourism_hashtag_pooling.dict\n",
      "2018-09-23 15:07:55,704 : INFO : loaded tourism_hashtag_pooling.dict\n",
      "2018-09-23 15:07:55,712 : INFO : loaded corpus index from tourism_hashtag_pooling.mm.index\n",
      "2018-09-23 15:07:55,714 : INFO : initializing cython corpus reader from tourism_hashtag_pooling.mm\n",
      "2018-09-23 15:07:55,717 : INFO : accepted corpus with 6198 documents, 9904 features, 84677 non-zero entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized no pooling corpus loaded!\n",
      "Vectorized user pooling corpus loaded!\n",
      "Vectorized hashtag pooling corpus loaded!\n"
     ]
    }
   ],
   "source": [
    "# load no pooling corpus\n",
    "if (os.path.exists(\"tourism_no_pooling.dict\")):\n",
    "   dictionary_no_pooling = corpora.Dictionary.load('tourism_no_pooling.dict')\n",
    "   corpus_no_pooling = corpora.MmCorpus('tourism_no_pooling.mm')\n",
    "   print(\"Vectorized no pooling corpus loaded!\")\n",
    "else:\n",
    "   print(\"Please run preprocessing script first!\")\n",
    "\n",
    "# load user pooling corpus\n",
    "if (os.path.exists(\"tourism_user_pooling.dict\")):\n",
    "   dictionary_user_pooling = corpora.Dictionary.load('tourism_user_pooling.dict')\n",
    "   corpus_user_pooling = corpora.MmCorpus('tourism_user_pooling.mm')\n",
    "   print(\"Vectorized user pooling corpus loaded!\")\n",
    "else:\n",
    "   print(\"Please run preprocessing script first!\")\n",
    "\n",
    "# load hashtag pooling corpus\n",
    "if (os.path.exists(\"tourism_hashtag_pooling.dict\")):\n",
    "   dictionary_hashtag_pooling = corpora.Dictionary.load('tourism_hashtag_pooling.dict')\n",
    "   corpus_hashtag_pooling = corpora.MmCorpus('tourism_hashtag_pooling.mm')\n",
    "   print(\"Vectorized hashtag pooling corpus loaded!\")\n",
    "else:\n",
    "   print(\"Please run preprocessing script first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-23 15:12:28,367 : WARNING : likelihood is decreasing!\n",
      "2018-09-23 15:12:28,370 : WARNING : likelihood is decreasing!\n",
      "2018-09-23 15:12:28,374 : WARNING : likelihood is decreasing!\n",
      "2018-09-23 15:12:36,665 : INFO : (0, \"0.002*#hairporn + 0.002*school + 0.002*lager + 0.002*i'm + 0.001*collectivesound + 0.001*hahahaha + 0.001*becomes + 0.001*trying + 0.001*zoo + 0.001*#haircut\")\n",
      "2018-09-23 15:12:36,672 : INFO : (1, '0.002*#parcdellaberint + 0.001*woke + 0.001*language + 0.001*esta + 0.001*current + 0.001*song + 0.001*#catalanreferendum + 0.001*maestro + 0.001*bro + 0.001*major')\n",
      "2018-09-23 15:12:36,682 : INFO : (2, '0.001*colores + 0.001*templo + 0.001*bucket + 0.001*cerca + 0.001*verdi + 0.001*#basilica + 0.001*son + 0.001*#vsco + 0.001*devotion + 0.001*//')\n",
      "2018-09-23 15:12:36,693 : INFO : (3, '0.002*#graphicdesign + 0.001*foot + 0.001*clínic + 0.001*big + 0.001*vía + 0.001*true + 0.001*worth + 0.001*#abirradero + 0.001*#traveltheworld + 0.001*#opiumbarcelona')\n",
      "2018-09-23 15:12:36,705 : INFO : (4, '0.002*#gracia + 0.002*torrades + 0.001*checking + 0.001*celebration + 0.001*catching + 0.001*#davidbowie + 0.001*#instalike + 0.001*cranny + 0.001*emerson_soc + 0.001*llevant')\n",
      "2018-09-23 15:12:36,714 : INFO : (5, '0.002*sagrada + 0.001*doubletree + 0.001*familia + 0.001*punk + 0.001*eno + 0.001*bona + 0.001*#holidays + 0.001*#spain2017 + 0.001*mapeando + 0.001*bommmmmbbbbb!')\n",
      "2018-09-23 15:12:36,726 : INFO : (6, \"0.002*chico + 0.001*men's + 0.001*#barcelona's + 0.001*voilà! + 0.001*#outandabout + 0.001*fun + 0.001*#tweegram + 0.001*pop + 0.001*double + 0.001*caesarbaetulo\")\n",
      "2018-09-23 15:12:36,737 : INFO : (7, '0.002*spaniard + 0.002*{#americanpsycho + 0.002*result + 0.001*#praise + 0.001*david + 0.001*temperature + 0.001*#chill + 0.001*#jenniferheels + 0.001*#bebcnbrand + 0.001*#artwork')\n",
      "2018-09-23 15:12:36,751 : INFO : (8, '0.002*sagrada + 0.002*happen + 0.001*street + 0.001*fear + 0.001*#iphoneonly + 0.001*#createyourownhappiness + 0.001*#streetphotography + 0.001*practicando + 0.001*estrelladammes + 0.001*#dirtysouth')\n",
      "2018-09-23 15:12:36,763 : INFO : (9, '0.002*mouth + 0.002*#colors + 0.001*beautiful!! + 0.001*chain + 0.001*dry + 0.001*plenty + 0.001*#lunch + 0.001*captain + 0.001*bump + 0.001*red')\n",
      "2018-09-23 15:12:36,779 : INFO : (10, '0.002*#team + 0.002*premiere + 0.002*#meditation + 0.001*ticket + 0.001*#gym + 0.001*extraordinary + 0.001*#meat + 0.001*overnight + 0.001*glass + 0.001*#sagradafamiliabarcelona')\n",
      "2018-09-23 15:12:36,789 : INFO : (11, '0.002*swim + 0.002*card + 0.002*nou + 0.002*(2017) + 0.001*#bracelona + 0.001*#spain2017 + 0.001*phone + 0.001*joan + 0.001*ipa) + 0.001*#gato')\n",
      "2018-09-23 15:12:36,803 : INFO : (12, '0.002*sagrada + 0.002*#lost + 0.001*#iulian + 0.001*following + 0.001*fact + 0.001*#dubai + 0.001*#barcelonabeachfestival2017 + 0.001*#silence + 0.001*#lightart + 0.001*#apiumhub')\n",
      "2018-09-23 15:12:36,814 : INFO : (13, '0.002*ruined + 0.002*sagrada + 0.002*manage + 0.001*painted + 0.001*palau + 0.001*#rooftop + 0.001*pas + 0.001*#pencil + 0.001*get + 0.001*tonight!!')\n",
      "2018-09-23 15:12:36,827 : INFO : (14, '0.002*#jamiroquai + 0.002*supper + 0.002*distillery + 0.001*#lasagradafamilia + 0.001*dumb + 0.001*closing + 0.001*moll + 0.001*#mimosa + 0.001*#casting + 0.001*#honeymoon')\n",
      "2018-09-23 15:12:36,836 : INFO : (15, '0.002*#goodtimes + 0.002*day + 0.002*headed + 0.001*dr + 0.001*hefeweizen + 0.001*nou + 0.001*enfants + 0.001*time! + 0.001*except + 0.001*hoy')\n",
      "2018-09-23 15:12:36,851 : INFO : (16, '0.002*realwashingtonbodero + 0.002*cocovail + 0.001*captain + 0.001*______ + 0.001*#tagsforlikesapp + 0.001*#dondiablo + 0.001*light + 0.001*looked + 0.001*anywhere + 0.001*trzech')\n",
      "2018-09-23 15:12:36,858 : INFO : (17, '0.002*paper + 0.001*sushi + 0.001*quarter + 0.001*#morning + 0.001*nativity + 0.001*whenever + 0.001*#vino + 0.001*barcelone + 0.001*hottie + 0.001*sunrise')\n",
      "2018-09-23 15:12:36,866 : INFO : (18, '0.002*empezamos + 0.002*#november + 0.002*feel + 0.001*shown + 0.001*bar + 0.001*#masterchef + 0.001*mundohr + 0.001*move + 0.001*#instagram + 0.001*date')\n",
      "2018-09-23 15:12:36,876 : INFO : (19, '0.002*click + 0.002*el + 0.001*#blackandwhitephotography + 0.001*sagrada + 0.001*weather + 0.001*#dondiablo + 0.001*soul + 0.001*passion + 0.001*learned + 0.001*ever')\n",
      "2018-09-23 15:12:36,983 : INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "2018-09-23 15:12:36,997 : INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "2018-09-23 15:12:37,011 : INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "2018-09-23 15:12:37,036 : INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "2018-09-23 15:12:37,058 : INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "2018-09-23 15:12:37,072 : INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "2018-09-23 15:12:37,093 : INFO : CorpusAccumulator accumulated stats from 7000 documents\n"
     ]
    }
   ],
   "source": [
    "model = HdpModel(corpus_no_pooling, dictionary_no_pooling)\n",
    "cm = CoherenceModel(model=model, corpus=corpus_no_pooling, coherence='u_mass')\n",
    "coherence = cm.get_coherence()  # get coherence value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'passes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-dce11e94c0a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHdpModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_hashtag_pooling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary_hashtag_pooling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_hashtag_pooling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'u_mass'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcoherence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# get coherence value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'passes'"
     ]
    }
   ],
   "source": [
    "model = HdpModel(corpus_hashtag_pooling, dictionary_hashtag_pooling)\n",
    "cm = CoherenceModel(model=model, corpus=corpus_hashtag_pooling, coherence='u_mass')\n",
    "coherence = cm.get_coherence()  # get coherence value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdpmodel.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = HdpModel(corpus_user_pooling, dictionary_user_pooling)\n",
    "cm = CoherenceModel(model=model, corpus=corpus_hashtag_pooling, coherence='u_mass')\n",
    "coherence = cm.get_coherence()  # get coherence value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tokenized_documents_district_pooling.p', 'rb') as fp:\n",
    "    district_pooling_docs = pickle.load(fp)\n",
    "    \n",
    "with open('tokenized_documents_month_pooling.p', 'rb') as fp:\n",
    "    month_pooling_docs = pickle.load(fp)\n",
    "    \n",
    "with open('tokenized_documents_district_per_month_pooling.p', 'rb') as fp:\n",
    "    district_per_month_pooling_docs = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to run hdp on test documents\n",
    "def run_hdp_on_test_doc(docs):\n",
    "    bow_list = [dictionary.doc2bow(text) for text in docs]\n",
    "    topic_list = []\n",
    "    \n",
    "    for index in range(len(bow_list)):\n",
    "        bow = bow_list[index]\n",
    "        topic_vector = hdp_model[bow]\n",
    "        topic_list.append(topic_vector)\n",
    "        \n",
    "    return topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_info = hdp.print_topics(num_topics=20, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsimodel = LsiModel(corpus=corpus, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsimodel.show_topics(num_topics=5)  # Showing only the top 5 topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
